{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pipeline workflow: EDA → preprocessing → DecisionTree & RandomForest training → Threshold tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, precision_recall_curve, average_precision_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/US_Heart_Patients.csv')\n",
    "print('Shape:', df.shape)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-point summary\n",
    "display(df.describe())\n",
    "\n",
    "# Info\n",
    "print(df.info())\n",
    "\n",
    "# Missing values per column\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Outlier counts (IQR method)\n",
    "num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "outlier_counts = {}\n",
    "for c in num_cols:\n",
    "    q1 = df[c].quantile(0.25)\n",
    "    q3 = df[c].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5 * iqr\n",
    "    high = q3 + 1.5 * iqr\n",
    "    outlier_counts[c] = int(((df[c] < low) | (df[c] > high)).sum())\n",
    "print(pd.Series(outlier_counts).sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "corr = df.select_dtypes(include=['number']).corr()\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdBu', center=0)\n",
    "plt.title('Correlation matrix (numeric features)')\n",
    "plt.show()\n",
    "\n",
    "# Distributions\n",
    "num_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "df[num_cols].hist(bins=20, figsize=(16,12))\n",
    "plt.suptitle('Numeric feature distributions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "if 'glucose' in df.columns:\n",
    "    df['glucose_missing'] = df['glucose'].isnull().astype(int)\n",
    "\n",
    "# Winsorization\n",
    "winsor_cols = ['tot cholesterol','Systolic BP','Diastolic BP','BMI','glucose']\n",
    "for c in winsor_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].clip(df[c].quantile(0.01), df[c].quantile(0.99))\n",
    "\n",
    "# Prepare X, y\n",
    "TARGET = 'Heart-Att'\n",
    "X = df.drop(columns=[TARGET])\n",
    "y = df[TARGET]\n",
    "if y.dtype == 'object' or y.dtype.name == 'category':\n",
    "    y = LabelEncoder().fit_transform(y.astype(str))\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['number']).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in numeric_cols]\n",
    "print('Numeric cols:', numeric_cols)\n",
    "print('Categorical cols:', cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=13)\n",
    "\n",
    "num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median'))])\n",
    "cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "preproc = ColumnTransformer([('num', num_pipe, numeric_cols), ('cat', cat_pipe, cat_cols)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree baseline + hyperparameter tuning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "dt_pipe = Pipeline([('preprocessor', preproc), ('clf', DecisionTreeClassifier(random_state=13))])\n",
    "\n",
    "dt_param_grid = {\n",
    "    'clf__max_depth': [3,5,7,None],\n",
    "    'clf__min_samples_split': [2,5,10],\n",
    "    'clf__min_samples_leaf': [1,2,5]\n",
    "}\n",
    "\n",
    "dt_grid = GridSearchCV(dt_pipe, dt_param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=13), scoring='f1', n_jobs=-1, verbose=1)\n",
    "print('Starting Decision Tree GridSearch...')\n",
    "dt_grid.fit(X_train, y_train)\n",
    "dt_best = dt_grid.best_estimator_\n",
    "print('Best DT params:', dt_grid.best_params_)\n",
    "\n",
    "# Evaluate\n",
    "y_train_pred = dt_best.predict(X_train)\n",
    "y_test_pred = dt_best.predict(X_test)\n",
    "print('Train F1:', f1_score(y_train, y_train_pred))\n",
    "print('Test F1:', f1_score(y_test, y_test_pred))\n",
    "print('Confusion matrix (test):')\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('Classification report (test):')\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save DT model\n",
    "joblib.dump(dt_best, '../models//decision_tree_model.pkl')\n",
    "print('Saved Decision Tree to ../models//decision_tree_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest with GridSearchCV\n",
    "rf_pipe = Pipeline([('preprocessor', preproc), ('clf', RandomForestClassifier(class_weight='balanced', random_state=13))])\n",
    "rf_param_grid = {'clf__n_estimators':[100,200], 'clf__max_depth':[5,10,None], 'clf__min_samples_split':[5,10], 'clf__min_samples_leaf':[2,5]}\n",
    "rf_grid = GridSearchCV(rf_pipe, rf_param_grid, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=13), scoring='f1', n_jobs=-1, verbose=1)\n",
    "\n",
    "print('Starting RandomForest GridSearch...')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "rf_best = rf_grid.best_estimator_\n",
    "print('Best RF params:', rf_grid.best_params_)\n",
    "\n",
    "# Default evaluation @0.5\n",
    "y_test_pred = rf_best.predict(X_test)\n",
    "print('F1 Test @0.5:', f1_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Probabilities and PR curve\n",
    "proba = rf_best.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(y_test, proba)\n",
    "ap = average_precision_score(y_test, proba)\n",
    "plt.figure(figsize=(7,6)); plt.plot(recall, precision, label=f'AP={ap:.3f}'); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "# Threshold sweep\n",
    "threshs = np.linspace(0.01,0.99,99)\n",
    "rows = []\n",
    "for t in threshs:\n",
    "    preds = (proba >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "    prec = precision_score(y_test, preds, zero_division=0)\n",
    "    rec = recall_score(y_test, preds, zero_division=0)\n",
    "    f1 = f1_score(y_test, preds, zero_division=0)\n",
    "    cost = fp * 1 + fn * 10\n",
    "    rows.append((t, tp, tn, fp, fn, prec, rec, f1, cost))\n",
    "th_df = pd.DataFrame(rows, columns=['threshold','tp','tn','fp','fn','precision','recall','f1','cost'])\n",
    "th_df.to_csv('../models/threshold_metrics.csv', index=False)\n",
    "\n",
    "def pick_thresholds(df, target_recall=0.8):\n",
    "    best_f1 = df.loc[df.f1.idxmax()]\n",
    "    candidates = df[df.recall >= target_recall]\n",
    "    best_recall = candidates.loc[candidates.precision.idxmax()] if not candidates.empty else None\n",
    "    best_cost = df.loc[df.cost.idxmin()]\n",
    "    return best_f1, best_recall, best_cost\n",
    "\n",
    "best_f1, best_recall, best_cost = pick_thresholds(th_df)\n",
    "print('Best F1 threshold:', best_f1.threshold, 'F1=', best_f1.f1)\n",
    "if best_recall is not None:\n",
    "    print('Recall-target threshold:', best_recall.threshold, 'recall=', best_recall.recall, 'precision=', best_recall.precision)\n",
    "else:\n",
    "    print('No threshold meets recall target')\n",
    "print('Cost-min threshold:', best_cost.threshold, 'cost=', best_cost.cost)\n",
    "\n",
    "# Save final RF model and selection\n",
    "selection = {'threshold_optimal_f1': float(best_f1.threshold), 'threshold_recall_target': float(best_recall.threshold) if best_recall is not None else None, 'threshold_cost_min': float(best_cost.threshold)}\n",
    "joblib.dump({'model': rf_best, 'threshold_selection': selection}, '../models/final_randomforest_model.pkl')\n",
    "print('Saved RandomForest model and threshold selection to ../models/final_randomforest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruned tree of the RandomForest (one tree approximation not directly available from ensemble)\n",
    "# We can visualize a single tree from the forest for interpretability\n",
    "clf = rf_best.named_steps['clf'] if hasattr(rf_best, 'named_steps') else rf_best\n",
    "# if pipeline, get classifier\n",
    "if isinstance(clf, Pipeline):\n",
    "    clf = clf.named_steps['clf']\n",
    "\n",
    "# plot tree 0 from the ensemble\n",
    "try:\n",
    "    estimator = clf.estimators_[0]\n",
    "    plt.figure(figsize=(18,10))\n",
    "    plot_tree(estimator, max_depth=3, filled=True, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"models\", exist_ok=True)   # <-- ensure folder exists\n",
    "    plt.savefig(\"models/tree_pruned.png\", dpi=200)\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(\"Could not plot tree from ensemble:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
